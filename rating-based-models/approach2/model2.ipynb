{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AreHG0XIgmS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd '/content/drive/My Drive/Colab Notebooks/official_v2/rating-based-models/approach2'\n",
        "!ls\n",
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sbag5I1XKedJ",
        "colab_type": "text"
      },
      "source": [
        "Read data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fw-l-krrLJ0b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data_folder = '../../datasets/rating-based-dataset/'\n",
        "\n",
        "scores_data = pd.read_csv(data_folder + \"data/ae_only_unambiguous_1000.csv\", low_memory=False)\n",
        "\n",
        "_images = scores_data['website'].unique()\n",
        "_scores = scores_data.groupby('website')['mean_response'].apply(list)\n",
        "\n",
        "del scores_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gb_mWVp8LH0B",
        "colab_type": "text"
      },
      "source": [
        "Get images path."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3XWHxswQA4-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_images = []\n",
        "scores = []\n",
        "images_path = data_folder + 'preprocess/resized'\n",
        "\n",
        "for image in _images:\n",
        "\n",
        "  # english websites\n",
        "  if 'english' in image:\n",
        "    all_images.append(images_path + '/english_resized/' + image[8:] + '.png')\n",
        "    scores.append(_scores[image])\n",
        "\n",
        "  # foreign websites\n",
        "  if 'foreign' in image:\n",
        "    all_images.append(images_path + '/foreign_resized/' + image[8:] + '.png')  \n",
        "    scores.append(_scores[image])\n",
        "\n",
        "print('Total number of images: %d' % len(all_images))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_e6UsYcL8vC",
        "colab_type": "text"
      },
      "source": [
        "Get the path of the images in test set and the ground truth user aesthetics ratings for each website. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyuWYt-nIvAQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "\n",
        "test_data_path = data_folder + 'preprocess/test_list.csv'\n",
        "\n",
        "def get_scores(scores_path):\n",
        "\n",
        "    images = []\n",
        "    scores = []\n",
        "\n",
        "    with open(scores_path) as csv_file:\n",
        "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "        line_count = 0\n",
        "\n",
        "        for row in csv_reader:\n",
        "            if line_count == 0:\n",
        "\n",
        "                line_count += 1\n",
        "            else:\n",
        "\n",
        "                scores.append(float(row[1]))\n",
        "                line_count += 1\n",
        "                image_name = row[0]\n",
        "\n",
        "                images.append(images_path + image_name)\n",
        "\n",
        "    return (images, scores)\n",
        "\n",
        "test_images_names, gt_scores = get_scores(test_data_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJWRPcNfM3QQ",
        "colab_type": "text"
      },
      "source": [
        "Form training and test data \n",
        "* {train, test}_images: contains the path of each image\n",
        "* {train, test}_scores: contains the user ratings of each image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNByZd3ySb2W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images =[]\n",
        "train_scores =[]\n",
        "\n",
        "test_images = test_images_names\n",
        "test_scores = [[]] * len(test_images)\n",
        "\n",
        "for i in range(0, len(all_images)):\n",
        "  if all_images[i] in test_images_names:\n",
        "\n",
        "    pos = test_images_names.index(all_images[i])\n",
        "\n",
        "    test_scores[pos] = scores[i]\n",
        "  else:\n",
        "    train_images.append(all_images[i])\n",
        "    train_scores.append(scores[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cyw633FEN4tS",
        "colab_type": "text"
      },
      "source": [
        "Shuffle the training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCe8KaAQTOvz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "\n",
        "# np.random.seed(2000)\n",
        "    \n",
        "temp = list(zip(train_images, train_scores))\n",
        "random.shuffle(temp)\n",
        "\n",
        "train_images, train_scores = zip(*temp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_403SqrZODcP",
        "colab_type": "text"
      },
      "source": [
        "Display the first 3 images to make sure everything is ok. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jpagl0HsTUEF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.image as mping\n",
        "for ima in train_images[0:3]:\n",
        "  img = mping.imread(ima)\n",
        "  imgplot = plt.imshow(img)\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_7mRFO6OG7i",
        "colab_type": "text"
      },
      "source": [
        "Read the images as numpy arrays"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dX0IUirtTaoL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "\n",
        "width = 256 \n",
        "height = 192 \n",
        "channels = 3\n",
        "\n",
        "def read_and_process_images(list_of_images):\n",
        "  X = []\n",
        "  \n",
        "  for image in list_of_images:\n",
        "\n",
        "    # images are already resized\n",
        "    # X.append(cv2.resize(cv2.imread(image, cv2.IMREAD_COLOR), (width, height), \n",
        "    #                     interpolation=cv2.INTER_AREA))\n",
        "    X.append(cv2.imread(image, cv2.IMREAD_COLOR))\n",
        "\n",
        "  \n",
        "  return X\n",
        "\n",
        "\n",
        "X_train = np.array(read_and_process_images(train_images))\n",
        "X_val = np.array(read_and_process_images(test_images))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6ZnqNCQOYyX",
        "colab_type": "text"
      },
      "source": [
        "Display the first 3 images to make sure everything is ok"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4wDCyQ1Tk_B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(25,15))\n",
        "columns = 3\n",
        "\n",
        "for i in range(columns):\n",
        "  plt.subplot(columns, 1, i+1)\n",
        "  plt.imshow(X_train[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMPV71kvPv5V",
        "colab_type": "text"
      },
      "source": [
        "The ground truth distribution of human ratings of a given website can be expressed as an empirical probability mass function **p** = [p<sub>s<sub>1</sub></sub>, p<sub>s<sub>2</sub></sub>, ..., p<sub>s<sub>N</sub></sub>] with s<sub>1</sub> &#8804; s<sub>i</sub> &#8804; s<sub>N</sub>, where s<sub>i</sub> denotes the i-th score bucket and N denotes the total number of buckets. In this case, s<sub>1</sub>=1 and s<sub>N</sub>=9.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQcRQ0uGUdvp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bins = [0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5, 9.5]\n",
        "score_values = np.array([1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0])\n",
        "\n",
        "y_train = []\n",
        "\n",
        "for i in range(0, len(train_scores)):\n",
        "  y_temp = np.histogram(train_scores[i], bins=bins)[0]\n",
        "  y_train.append(y_temp / len(train_scores[i]))\n",
        "  del y_temp\n",
        "\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "y_val = []\n",
        "\n",
        "for i in range(0, len(test_scores)):\n",
        "  y_temp = np.histogram(test_scores[i], bins=bins)[0]\n",
        "  y_val.append(y_temp / len(test_scores[i]))\n",
        "  del y_temp\n",
        "\n",
        "y_val = np.array(y_val)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hI3pIgLcPR9V",
        "colab_type": "text"
      },
      "source": [
        "Display shapes to check everything is ok"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzQsQb8jXR0O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ntrain = len(X_train)\n",
        "nval = len(X_val)\n",
        "\n",
        "print('Shape of X_train is: ', X_train.shape)\n",
        "print('Shape of X_val is: ', X_val.shape)\n",
        "print('Shape of y_train is: ', y_train.shape)\n",
        "print('Shape of y_val is: ', y_val.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZOkPsEkUpEO",
        "colab_type": "text"
      },
      "source": [
        "Construct the CNN. The task is to predict the user aesthetics score distribution for a website. We will use [NIMA-MobileNet](https://arxiv.org/pdf/1709.05424.pdf) as our base network. This network is pretrained on AVA dataset (containing 255k image with aesthetic quality ratings) for the neural image assessment task."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6Q1cwyBXTf-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications.mobilenet import MobileNet\n",
        "from keras import optimizers\n",
        "from keras import regularizers\n",
        "from keras.layers import GlobalMaxPooling2D, Dense, Dropout, Flatten\n",
        "from keras.models import Model\n",
        "\n",
        "input_shape = X_train[0].shape\n",
        "\n",
        "base_model = MobileNet(include_top=False, weights='imagenet', pooling='avg', input_shape=input_shape)\n",
        "\n",
        "x = base_model.output\n",
        "x = Dropout(0.6)(x) \n",
        "outputs = Dense(10, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=outputs)\n",
        "model.load_weights('../../pretrained-models/mobilenet_weights.h5')\n",
        "\n",
        "model.layers.pop()\n",
        "outputs = Dense(9, activation='softmax')(model.layers[-1].output)\n",
        "model = Model(inputs=model.input, outputs=outputs)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEgCsP2BQQqC",
        "colab_type": "text"
      },
      "source": [
        "Define the loss function (Earth Mover's Distance)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dNk-tMUYqIO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def earth_mover_loss(y_true, y_pred):\n",
        "    cdf_ytrue = K.cumsum(y_true, axis=-1)\n",
        "    cdf_ypred = K.cumsum(y_pred, axis=-1)\n",
        "    samplewise_emd = K.sqrt(K.mean(K.square(K.abs(cdf_ytrue - cdf_ypred)), axis=-1))\n",
        "    return K.mean(samplewise_emd)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CD7wYIIYo6N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "val_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "train_generator = train_datagen.flow(X_train, y_train, batch_size=batch_size)\n",
        "val_generator = val_datagen.flow(X_val, y_val, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKhZY81oRI0H",
        "colab_type": "text"
      },
      "source": [
        "Compile the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDQpMQmhYvvt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 95\n",
        "decay = 1e-4 \n",
        "base_lr = 0.005\n",
        "\n",
        "sgd = optimizers.SGD(lr=base_lr, momentum=0.9, decay=decay, nesterov=True)\n",
        "model.compile(loss=earth_mover_loss, optimizer=sgd, metrics=[earth_mover_loss])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYlMYn33RjLb",
        "colab_type": "text"
      },
      "source": [
        "Train the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_YzT0JCY90w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit_generator(train_generator, \n",
        "                             steps_per_epoch = ntrain // batch_size,\n",
        "                             epochs = epochs, \n",
        "                             validation_data=val_generator,\n",
        "                             validation_steps=nval // batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1cjrIIFRgRu",
        "colab_type": "text"
      },
      "source": [
        "Display the learning curves."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLPuiYC3ZIRo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "emd = history.history[\"earth_mover_loss\"]\n",
        "val_emd = history.history[\"val_earth_mover_loss\"]\n",
        "\n",
        "epochs_x = range(1, len(emd) + 1)\n",
        "\n",
        "plt.plot(epochs_x, emd, 'b', label='Training EMD')\n",
        "plt.plot(epochs_x, val_emd, 'r', label='Validation EMD')\n",
        "\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lViPMAw6RlWj",
        "colab_type": "text"
      },
      "source": [
        "Define a function that calculates Pearson correlation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGVyHN0WcWVG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy import stats\n",
        "\n",
        "def pearsonr_ci(x,y,alpha=0.05):\n",
        "    ''' calculate Pearson correlation along with the confidence interval using scipy and numpy\n",
        "    Parameters\n",
        "    ----------\n",
        "    x, y : iterable object such as a list or np.array\n",
        "      Input for correlation calculation\n",
        "    alpha : float\n",
        "      Significance level. 0.05 by default\n",
        "    Returns\n",
        "    -------\n",
        "    r : float\n",
        "      Pearson's correlation coefficient\n",
        "    pval : float\n",
        "      The corresponding p value\n",
        "    lo, hi : float\n",
        "      The lower and upper bound of confidence intervals\n",
        "    '''\n",
        "    N = len(x)\n",
        "    r, p = stats.pearsonr(x,y)\n",
        "    r_z = np.arctanh(r)\n",
        "    se = 1/np.sqrt(N-3)\n",
        "    z = stats.norm.ppf(1-alpha/2)\n",
        "    lo_z, hi_z = r_z-z*se, r_z+z*se\n",
        "    lo, hi = np.tanh((lo_z, hi_z))\n",
        "    return r, p, lo, hi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fv4ksCj26_D0",
        "colab_type": "text"
      },
      "source": [
        "Predict aesthetics score of the webpages in the test set. The mean value of the predicted distribution is used as the final aesthetics score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANebT-tBcfOn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = []\n",
        "\n",
        "X_val = X_val / 255.0\n",
        "\n",
        "for img in X_val:\n",
        "  img = img.reshape(1, 192, 256, 3)\n",
        "  pred = model.predict(img)\n",
        "\n",
        "  predictions.append(float(np.sum(pred[0] * score_values)))\n",
        "\n",
        "gt_scores = np.array(gt_scores)\n",
        "predictions = np.array(predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeM28l7kZ4Ti",
        "colab_type": "text"
      },
      "source": [
        "Display some websites of the test set and the predicted aesthetics score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJJW6_BlGO5_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_ids = [87, 45, 49, 94, 14, 83] # test image IDs sorted in descending order according to the website's aesthetics level\n",
        "\n",
        "fig = plt.figure(figsize=(12, 16))\n",
        "i = 1\n",
        "for id in image_ids:\n",
        "  if 'english' in test_images[id]:\n",
        "    path = images_path + '/english_resized/' + test_images[id].rsplit('/', 1)[1]\n",
        "  else:\n",
        "    path = images_path + '/foreign_resized/' + test_images[id].rsplit('/', 1)[1]\n",
        " \n",
        "  plt.subplot(len(image_ids)/2, 2, i)\n",
        "  img = mping.imread(path)\n",
        "  plt.title('User average rating: ' + str(np.round(gt_scores[id],2)) + '\\nPredicted rating: ' + str(np.round(predictions[id],2)) + '\\n(' + chr(97+i-1) + ')', y=-0.25)\n",
        "  plt.axis('off')\n",
        "  plt.imshow(img)\n",
        "    \n",
        "  i += 1\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLAvK-W6R_Ye",
        "colab_type": "text"
      },
      "source": [
        "Create a scatterplot to check the relationship between ground truth and predicted scores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MT2GU-J5c5a8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy.polynomial.polynomial import polyfit\n",
        "b, m = polyfit(gt_scores, predictions, 1)\n",
        "\n",
        "fig = plt.figure()\n",
        "plt.scatter(gt_scores, predictions, c='c')\n",
        "plt.plot(gt_scores, b + m * gt_scores, '-', c='b')\n",
        "plt.xlabel('User ratings')\n",
        "plt.ylabel('Predicted ratings')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_copvG3R2oE",
        "colab_type": "text"
      },
      "source": [
        "Calculate the Pearson correlation and the RMSE between ground truth and predicted scores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJJ2uK50c6No",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "\n",
        "\n",
        "corr, p, lo, hi = pearsonr_ci(gt_scores, predictions)\n",
        "print('Pearsons correlation: r=%.2f, p=%.2e, CI=[%.2f, %.2f]' % (corr, p, lo, hi))\n",
        "rmse_test = sqrt(mean_squared_error(gt_scores, predictions))\n",
        "print('RMSE: %.3f' % rmse_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTcz-4TaSF7g",
        "colab_type": "text"
      },
      "source": [
        "Plot the distribution of ground truth scores and the distribution of predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2wRKCK7klRo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import seaborn as sns\n",
        "\n",
        "fig = plt.figure()\n",
        "sns.set(color_codes=True)\n",
        "\n",
        "bins = np.linspace(1, 9, num=15)\n",
        "\n",
        "sns.distplot(gt_scores, bins=bins, label='User ratings')\n",
        "\n",
        "sns.distplot(predictions, bins=bins, label='Predicted ratings')\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}